{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import  RunnablePassthrough\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "from neo4j import GraphDatabase\n",
    "from yfiles_jupyter_graphs import GraphWidget\n",
    "from langchain_community.vectorstores import Neo4jVector\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores.neo4j_vector import remove_lucene_chars\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "import os\n",
    "from langchain_experimental.llms.ollama_functions import OllamaFunctions\n",
    "from neo4j import  Driver\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Neo4jGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm_llama70b = ChatOpenAI(\n",
    "    base_url=\"https://api.together.xyz/v1\", #https://api.together.xyz\n",
    "    api_key=os.environ[\"TOGETHER_API_KEY\"],\n",
    "    model=\"meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo\",\n",
    "    temperature=0,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_transformer_llama70b = LLMGraphTransformer(llm=llm_llama70b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = TextLoader(file_path=\"data/capitulo1.txt\")\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1024, chunk_overlap=24)\n",
    "documents = text_splitter.split_documents(documents=docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_documents = llm_transformer_llama70b.convert_to_graph_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphDocument(nodes=[Node(id='Úrsula', type='Person', properties={}), Node(id='Los Gitanos', type='Group', properties={}), Node(id='Melquíades', type='Person', properties={}), Node(id='La Población', type='Group', properties={})], relationships=[Relationship(source=Node(id='Úrsula', type='Person', properties={}), target=Node(id='La Población', type='Group', properties={}), type='INFLUENCED', properties={}), Relationship(source=Node(id='Los Gitanos', type='Group', properties={}), target=Node(id='Melquíades', type='Person', properties={}), type='TRANSFORMED', properties={}), Relationship(source=Node(id='Melquíades', type='Person', properties={}), target=Node(id='La Población', type='Group', properties={}), type='AMAZED', properties={})], source=Document(metadata={'source': 'parrafo_5.txt'}, page_content='Cuando volvieron los gitanos, Úrsula había predispuesto contra ellos a toda la población. Pero la curiosidad pudo más que el temor, porque aquella vez los gitanos recorrieron la aldea haciendo un ruido ensordecedor con toda clase de instrumentos músicos, mientras el pregonero anunciaba la exhibición del más fabuloso hallazgo de los nasciancenos. De modo que todo el mundo se fue a la carpa, y mediante el pago de un centavo vieron un Melquíades juvenil, repuesto, desarrugado, con una dentadura nueva y radiante. Quienes recordaban sus encías destruidas por el escorbuto, sus mejillas flaccidas y sus labios marchitos, se estremecieron de pavor ante aquella prueba terminante de los poderes sobrenaturales del gitano. El pavor se convirtió en pánico cuando Melquíades se sacó los dientes, intactos, engastados en las encías, y se los mostró al público por un instante un instante fugaz en que volvió a ser el mismo hombre decrépito de los años anteriores y se los puso otra vez y sonrió de nuevo con un dominio pleno de su'))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.add_graph_documents(\n",
    "    graph_documents,\n",
    "    baseEntityLabel=True,\n",
    "    include_source=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showGrath():\n",
    "    driver = GraphDatabase.driver(\n",
    "        uri = os.environ[\"NEO4J_URI\"],\n",
    "        auth = (os.environ[\"NEO4J_USERNAME\"],\n",
    "                os.environ[\"NEO4J_PASSWORD\"]))\n",
    "    session = driver.session()\n",
    "    widget = GraphWidget(graph = session.run(\"MATCH (s)-[r:!MENTIONS]->(t) RETURN s,r,t\").graph())\n",
    "    widget.node_label_mapping = 'id'\n",
    "    return widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20912ce2a9d4465688132329c07389ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GraphWidget(layout=Layout(height='800px', width='100%'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "showGrath()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OllamaEmbeddings(\n",
    "    model=\"mxbai-embed-large\",\n",
    ")\n",
    "\n",
    "vector_index = Neo4jVector.from_existing_graph(\n",
    "    embeddings,\n",
    "    search_type=\"hybrid\",\n",
    "    node_label=\"Document\",\n",
    "    text_node_properties=[\"text\"],\n",
    "    embedding_node_property=\"embedding\"\n",
    ")\n",
    "vector_retriever = vector_index.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = GraphDatabase.driver(\n",
    "        uri = os.environ[\"NEO4J_URI\"],\n",
    "        auth = (os.environ[\"NEO4J_USERNAME\"],\n",
    "                os.environ[\"NEO4J_PASSWORD\"]))\n",
    "\n",
    "def create_fulltext_index(tx):\n",
    "    query = '''\n",
    "    CREATE FULLTEXT INDEX `fulltext_entity_id` \n",
    "    FOR (n:__Entity__) \n",
    "    ON EACH [n.id];\n",
    "    '''\n",
    "    tx.run(query)\n",
    "\n",
    "# Function to execute the query\n",
    "def create_index():\n",
    "    with driver.session() as session:\n",
    "        session.execute_write(create_fulltext_index)\n",
    "        print(\"Fulltext index created successfully.\")\n",
    "\n",
    "# Call the function to create the index\n",
    "try:\n",
    "    create_index()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Close the driver connection\n",
    "driver.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_exp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
